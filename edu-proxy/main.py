# main.py - ç®€åŒ–ç¨³å®šç‰ˆ
import os
import json
import httpx
import asyncio
from typing import Optional, Dict, Any
from urllib.parse import urljoin, urlparse

from fastapi import FastAPI, HTTPException, Request, Query
from fastapi.responses import JSONResponse, Response, HTMLResponse
from fastapi.middleware.cors import CORSMiddleware

# åˆå§‹åŒ–åº”ç”¨
app = FastAPI(
    title="æ•™åŠ¡ç³»ç»Ÿä»£ç†",
    version="1.0.0",
    docs_url="/docs",
    redoc_url=None
)

# è·¨åŸŸè®¾ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é…ç½®
BASE_URL = "http://qzjw.bwgl.cn/gllgdxbwglxy_jsxsd/"

# åˆ›å»ºHTTPå®¢æˆ·ç«¯ä¼šè¯
class HttpClient:
    _client: Optional[httpx.AsyncClient] = None
    
    @classmethod
    async def get_client(cls):
        if cls._client is None:
            cls._client = httpx.AsyncClient(
                timeout=30.0,
                headers={
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                    "Accept-Language": "zh-CN,zh;q=0.9",
                    "Connection": "keep-alive",
                },
                follow_redirects=True,
                verify=False
            )
        return cls._client
    
    @classmethod
    async def close(cls):
        if cls._client:
            await cls._client.aclose()

# åº”ç”¨ç”Ÿå‘½å‘¨æœŸ
@app.on_event("startup")
async def startup_event():
    print("ğŸš€ æ•™åŠ¡ä»£ç†æœåŠ¡å¯åŠ¨")
    print(f"ğŸ“¡ ä»£ç†ç›®æ ‡: {BASE_URL}")
    print(f"ğŸ”§ Pythonç‰ˆæœ¬: 3.8")

@app.on_event("shutdown")
async def shutdown_event():
    await HttpClient.close()
    print("ğŸ‘‹ æœåŠ¡å…³é—­")

# 1. é¦–é¡µ
@app.get("/")
async def root():
    """æœåŠ¡é¦–é¡µ"""
    return {
        "service": "æ•™åŠ¡ç³»ç»Ÿä»£ç†æœåŠ¡",
        "status": "running",
        "proxy_target": BASE_URL,
        "endpoints": {
            "GET /health": "å¥åº·æ£€æŸ¥",
            "GET /proxy/{path}": "é€šç”¨ä»£ç†æ¥å£",
            "GET /api/{path}": "APIä»£ç†æ¥å£",
            "GET /fetch": "è·å–é¡µé¢å†…å®¹",
            "GET /analyze": "åˆ†æç½‘ç«™ç»“æ„"
        },
        "docs": "/docs"
    }

# 2. å¥åº·æ£€æŸ¥ï¼ˆRailwayå¿…é¡»ï¼‰
@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {
        "status": "healthy",
        "timestamp": asyncio.get_event_loop().time(),
        "service": "edu-proxy"
    }

# 3. æ ¸å¿ƒä»£ç†æ¥å£
@app.api_route("/proxy/{path:path}", methods=["GET", "POST"])
async def proxy_handler(
    path: str,
    request: Request,
    action: Optional[str] = Query(None),
    oper: Optional[str] = Query(None)
):
    """
    é€šç”¨ä»£ç†å¤„ç†å™¨
    path: ç›®æ ‡è·¯å¾„ï¼Œå¦‚ï¼šxkglAction.do
    action/oper: æ•™åŠ¡ç³»ç»Ÿå¸¸ç”¨å‚æ•°
    """
    try:
        # æ„å»ºç›®æ ‡URL
        target_url = urljoin(BASE_URL, path)
        
        # å¤„ç†æŸ¥è¯¢å‚æ•°
        query_params = dict(request.query_params)
        
        # å¤„ç†POSTæ•°æ®
        body = None
        if request.method == "POST":
            content_type = request.headers.get("content-type", "")
            if "application/json" in content_type:
                body = await request.json()
            elif "application/x-www-form-urlencoded" in content_type:
                form_data = await request.form()
                body = dict(form_data)
            else:
                body = await request.body()
        
        # è·å–HTTPå®¢æˆ·ç«¯
        client = await HttpClient.get_client()
        
        # å‘é€è¯·æ±‚
        response = await client.request(
            method=request.method,
            url=target_url,
            params=query_params,
            json=body if isinstance(body, dict) else None,
            data=body if isinstance(body, (dict, str)) else None,
            content=body if isinstance(body, bytes) else None
        )
        
        # è¿”å›å“åº”
        response_headers = dict(response.headers)
        
        # ç§»é™¤ä¸éœ€è¦çš„å¤´éƒ¨
        for key in ["content-encoding", "transfer-encoding"]:
            response_headers.pop(key, None)
        
        return Response(
            content=response.content,
            status_code=response.status_code,
            headers=response_headers
        )
        
    except httpx.RequestError as e:
        raise HTTPException(status_code=502, detail=f"è¯·æ±‚ç›®æ ‡ç½‘ç«™å¤±è´¥: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä»£ç†å¤„ç†é”™è¯¯: {str(e)}")

# 4. ç®€åŒ–ç‰ˆé¡µé¢è·å–
@app.get("/fetch")
async def fetch_page(
    url: str = Query(..., description="è¦è·å–çš„URLè·¯å¾„"),
    format: str = Query("json", description="è¿”å›æ ¼å¼: json æˆ– html")
):
    """è·å–é¡µé¢å†…å®¹"""
    try:
        # å¤„ç†URL
        if not url.startswith("http"):
            target_url = urljoin(BASE_URL, url)
        else:
            target_url = url
        
        client = await HttpClient.get_client()
        response = await client.get(target_url)
        
        if format == "html":
            return HTMLResponse(content=response.text)
        
        return {
            "url": target_url,
            "status_code": response.status_code,
            "content_length": len(response.content),
            "headers": dict(response.headers),
            "preview": response.text[:500] + "..." if len(response.text) > 500 else response.text
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# 5. ç½‘ç«™ç»“æ„åˆ†æ
@app.get("/analyze")
async def analyze():
    """åˆ†æç›®æ ‡ç½‘ç«™ç»“æ„"""
    try:
        client = await HttpClient.get_client()
        response = await client.get(BASE_URL)
        
        import re
        from bs4 import BeautifulSoup
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # åŸºæœ¬ä¿¡æ¯
        result = {
            "base_url": BASE_URL,
            "title": soup.title.string if soup.title else "æ— æ ‡é¢˜",
            "has_login_form": False,
            "links_count": 0,
            "forms_count": 0
        }
        
        # æŸ¥æ‰¾ç™»å½•è¡¨å•
        forms = soup.find_all('form')
        result["forms_count"] = len(forms)
        
        for form in forms:
            form_html = str(form).lower()
            if any(keyword in form_html for keyword in ['login', 'logon', 'signin', 'password']):
                result["has_login_form"] = True
                result["login_action"] = form.get('action', '')
                break
        
        # æå–é“¾æ¥
        links = []
        for a in soup.find_all('a', href=True):
            href = a['href']
            if href and not href.startswith(('javascript:', '#')):
                full_url = urljoin(BASE_URL, href)
                links.append({
                    "text": a.get_text(strip=True)[:50],
                    "href": href,
                    "full_url": full_url
                })
        
        result["links_count"] = len(links)
        result["sample_links"] = links[:10]  # åªè¿”å›å‰10ä¸ª
        
        # æå–å¯èƒ½çš„APIç«¯ç‚¹
        patterns = [
            r'(\w+Action\.do\??\w*=?\w*)',
            r'(\w+\.action\??\w*=?\w*)',
            r'(\w+\.jsp\??\w*=?\w*)',
            r'(\w+\.aspx\??\w*=?\w*)'
        ]
        
        endpoints = set()
        for pattern in patterns:
            matches = re.findall(pattern, response.text)
            endpoints.update(matches)
        
        result["endpoints"] = list(endpoints)[:20]  # æœ€å¤šè¿”å›20ä¸ª
        
        return result
        
    except Exception as e:
        return {"error": str(e), "base_url": BASE_URL}

# 6. æµ‹è¯•æ•™åŠ¡ç³»ç»Ÿå¸¸ç”¨æ¥å£
@app.get("/test/common")
async def test_common_endpoints():
    """æµ‹è¯•æ•™åŠ¡ç³»ç»Ÿå¸¸ç”¨æ¥å£"""
    endpoints = [
        "xkglAction.do?oper=xkgl_ckKb",      # æŸ¥çœ‹è¯¾è¡¨
        "xkglAction.do?oper=xkgl_cxXsxk",    # å­¦ç”Ÿé€‰è¯¾
        "xsxkAction.do",                     # å­¦ç”Ÿé€‰è¯¾ä¸»é¡µé¢
        "gradeLnAllAction.do",               # æˆç»©æŸ¥è¯¢
        "xsdjAction.do",                     # å­¦ç”Ÿç™»è®°
        "xskbcxAction.do",                   # å­¦ç”Ÿè¯¾è¡¨æŸ¥è¯¢
    ]
    
    results = []
    client = await HttpClient.get_client()
    
    for endpoint in endpoints[:3]:  # åªæµ‹è¯•å‰3ä¸ªé¿å…è¶…æ—¶
        try:
            url = urljoin(BASE_URL, endpoint)
            response = await client.get(url, timeout=10.0)
            results.append({
                "endpoint": endpoint,
                "status": response.status_code,
                "size": len(response.content),
                "title": BeautifulSoup(response.text, 'html.parser').title.string if BeautifulSoup(response.text, 'html.parser').title else "æ— æ ‡é¢˜"
            })
        except Exception as e:
            results.append({
                "endpoint": endpoint,
                "status": "error",
                "error": str(e)
            })
    
    return {
        "tested": len(results),
        "results": results
    }

# é”™è¯¯å¤„ç†
@app.exception_handler(404)
async def not_found(request: Request, exc):
    return JSONResponse(
        status_code=404,
        content={"error": "æ¥å£ä¸å­˜åœ¨", "path": request.url.path}
    )

# ä¸»ç¨‹åºå…¥å£
if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8000))
    print(f"Starting server on port {port}")
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=port,
        workers=1  # Railwayå»ºè®®ä½¿ç”¨1ä¸ªworker
    )